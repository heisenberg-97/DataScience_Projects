{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moneyball Playoffs Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download the dataset from https://www.kaggle.com/wduckett/moneyball-mlb-stats-19622012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of the code below:**\n",
    "\n",
    "1. Importing dependencies and acquiring data\n",
    "2. Performing EDA\n",
    "3. Filling the missing values of significant features with Regression Imputation\n",
    "4. Distributing data based on the two leagues mentioned in the categorical feature of 'League'\n",
    "5. Performing modelling over American League and National League subsets with Logistic Regression and GBDT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules and packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import mean_absolute_error , mean_squared_error\n",
    "from sklearn.metrics import accuracy_score , log_loss\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "pd.set_option('display.min_rows', 100)\n",
    "pd.set_option('display.max_columns', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Acquisition & Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>RankSeason</th>\n",
       "      <th>RankPlayoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs  RankSeason  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0         NaN   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1         4.0   \n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1         5.0   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0         NaN   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0         NaN   \n",
       "\n",
       "   RankPlayoffs    G   OOBP   OSLG  \n",
       "0           NaN  162  0.317  0.415  \n",
       "1           5.0  162  0.306  0.378  \n",
       "2           4.0  162  0.315  0.403  \n",
       "3           NaN  162  0.331  0.428  \n",
       "4           NaN  162  0.335  0.424  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball = pd.read_csv('moneyball.csv')\n",
    "#moneyball.shape\n",
    "moneyball.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team              0\n",
       "League            0\n",
       "Year              0\n",
       "RS                0\n",
       "RA                0\n",
       "W                 0\n",
       "OBP               0\n",
       "SLG               0\n",
       "BA                0\n",
       "Playoffs          0\n",
       "RankSeason      988\n",
       "RankPlayoffs    988\n",
       "G                 0\n",
       "OOBP            812\n",
       "OSLG            812\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So here we have NA values in 4 columns. Two of which are significant features (OOBP and OSLG) while the other two are insignificant. Since the number of missing values are far more, I decide to drop the insignificant ones and perform Linear Regression for filling up the values of OOBP and OSLG features.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression for OOBP and OSLG values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After dropping all the NA we're left with just 420 rows\n",
    "\n",
    "moneyball1=moneyball.drop(columns = ['Team','League','Year','RankSeason','RankPlayoffs','Playoffs'])\n",
    "moneyball1.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6., 14., 36., 92., 82., 82., 61., 31., 14.,  2.]),\n",
       " array([0.346 , 0.3613, 0.3766, 0.3919, 0.4072, 0.4225, 0.4378, 0.4531,\n",
       "        0.4684, 0.4837, 0.499 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.hist(moneyball1['OOBP'])\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(moneyball1['OSLG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OOBP and OSLG features are significant but have 812 missing values (from 1232 rows)\n",
    "Hence, carrying out Linear Regression for those two columns in order to predict and add those 812 values (Regression Imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset containing the remaining 420 rows into train and test data for OOBP\n",
    "\n",
    "x_train_OOBP,x_test_OOBP,y_train_OOBP,y_test_OOBP = train_test_split(moneyball1.drop(columns=['OOBP','OSLG']),moneyball1['OOBP']\n",
    "                                                                     ,test_size = 0.1, random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling the dataset for OOBP\n",
    "\n",
    "reg1 = LinearRegression()\n",
    "reg1.fit(x_train_OOBP,y_train_OOBP)\n",
    "\n",
    "predict_test_OOBP = reg1.predict(x_test_OOBP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset containing the remaining 420 rows into train and test data for OSLG\n",
    "\n",
    "x_train_OSLG,x_test_OSLG,y_train_OSLG,y_test_OSLG = train_test_split(moneyball1.drop(columns=['OOBP','OSLG']),moneyball1['OSLG']\n",
    "                                                                     ,test_size = 0.1, random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling the dataset for OSLG\n",
    "\n",
    "reg2 = LinearRegression()\n",
    "reg2.fit(x_train_OSLG,y_train_OSLG)\n",
    "\n",
    "predict_test_OSLG = reg2.predict(x_test_OSLG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rates for OOBP \n",
      " Mean Squared error -  3.336348939130085e-05 \n",
      " Mean Abs Error -  0.004375215360776467\n",
      "\n",
      " Error rates for OSLG \n",
      " Mean Squared error -  0.00011560582513692498 \n",
      " Mean Abs Error -  0.008385228010079187\n"
     ]
    }
   ],
   "source": [
    "# Error rates of the test OOBP & OSLG values.\n",
    "\n",
    "print('Error rates for OOBP','\\n','Mean Squared error - ',mean_squared_error(y_test_OOBP,predict_test_OOBP),\n",
    "      '\\n','Mean Abs Error - ', mean_absolute_error(y_test_OOBP,predict_test_OOBP))\n",
    "\n",
    "print('\\n','Error rates for OSLG','\\n','Mean Squared error - ',mean_squared_error(y_test_OSLG,predict_test_OSLG),\n",
    "      '\\n','Mean Abs Error - ', mean_absolute_error(y_test_OSLG,predict_test_OSLG))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above error rates indicate that the model built for filling up the NA values in OOBP & OSLG columns is performing well.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>G</th>\n",
       "      <th>OOBP</th>\n",
       "      <th>OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RS   RA   W    OBP    SLG     BA    G   OOBP   OSLG\n",
       "0  734  688  81  0.328  0.418  0.259  162  0.317  0.415\n",
       "1  700  600  94  0.320  0.389  0.247  162  0.306  0.378\n",
       "2  712  705  93  0.311  0.417  0.247  162  0.315  0.403\n",
       "3  734  806  69  0.315  0.415  0.260  162  0.331  0.428\n",
       "4  613  759  61  0.302  0.378  0.240  162  0.335  0.424"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Upon having a look at the dataset, we see that the OOBP and OSLG have NA values starting from the row #420.\n",
    "\n",
    "Selecting all the rows for which OOBP and OSLG had their values missing (812 rows) and \n",
    "feeding the value of their respective features to the trained Linear Regression models for prediction.\n",
    "\n",
    "'''\n",
    "\n",
    "moneyball2 = moneyball.drop(columns = ['Team','League','Year','RankSeason','RankPlayoffs','Playoffs','OOBP','OSLG'])\n",
    "x_OOBP_OSLG = moneyball2.iloc[420:,:]\n",
    "\n",
    "\n",
    "################################## Predicting for OOBP ############################################\n",
    "\n",
    "predict_OOBP = reg1.predict(x_OOBP_OSLG)\n",
    "\n",
    "################################### Predicting for OSLG ############################################\n",
    "\n",
    "predict_OSLG = reg2.predict(x_OOBP_OSLG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Indexing the OOBP and OSLG column from the dataset with dropped NA (420 rows) and appending it with the predicted values \n",
    "of OOBP and OSLG respectively.\n",
    "   \n",
    "'''\n",
    "\n",
    "a = moneyball1['OOBP']\n",
    "new_OOBP = np.append(a,predict_OOBP)\n",
    "\n",
    "c = moneyball1['OSLG']\n",
    "new_OSLG = np.append(c,predict_OSLG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_OOBP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1232,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_OSLG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Replacing the updated columns and cleaning the dataset #############################\n",
    "\n",
    "moneyball3 = moneyball.drop(columns=['OOBP','OSLG','RankSeason','RankPlayoffs'])\n",
    "moneyball3['new_OOBP'] = new_OOBP\n",
    "moneyball3['new_OSLG'] = new_OSLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a new dataset with all the OOBP and OSLG values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Team        0\n",
       "League      0\n",
       "Year        0\n",
       "RS          0\n",
       "RA          0\n",
       "W           0\n",
       "OBP         0\n",
       "SLG         0\n",
       "BA          0\n",
       "Playoffs    0\n",
       "G           0\n",
       "new_OOBP    0\n",
       "new_OSLG    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NL', 'AL'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball3.League.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since there are 2 major leagues given in the dataset i.e. National League and American League, we will split the dataset and work on them individually.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling for National League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>new_OOBP</th>\n",
       "      <th>new_OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARI</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHC</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CIN</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>669</td>\n",
       "      <td>588</td>\n",
       "      <td>97</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.251</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>COL</td>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>758</td>\n",
       "      <td>890</td>\n",
       "      <td>64</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs    G  \\\n",
       "0  ARI     NL  2012  734  688  81  0.328  0.418  0.259         0  162   \n",
       "1  ATL     NL  2012  700  600  94  0.320  0.389  0.247         1  162   \n",
       "4  CHC     NL  2012  613  759  61  0.302  0.378  0.240         0  162   \n",
       "6  CIN     NL  2012  669  588  97  0.315  0.411  0.251         1  162   \n",
       "8  COL     NL  2012  758  890  64  0.330  0.436  0.274         0  162   \n",
       "\n",
       "   new_OOBP  new_OSLG  \n",
       "0     0.317     0.415  \n",
       "1     0.306     0.378  \n",
       "4     0.335     0.424  \n",
       "6     0.305     0.390  \n",
       "8     0.357     0.470  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball_temp1 = moneyball3.loc[moneyball3['League']=='NL'].copy()  \n",
    "moneyball_temp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>new_OOBP</th>\n",
       "      <th>new_OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>734</td>\n",
       "      <td>688</td>\n",
       "      <td>81</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>700</td>\n",
       "      <td>600</td>\n",
       "      <td>94</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>613</td>\n",
       "      <td>759</td>\n",
       "      <td>61</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>669</td>\n",
       "      <td>588</td>\n",
       "      <td>97</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.251</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>758</td>\n",
       "      <td>890</td>\n",
       "      <td>64</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RS   RA   W    OBP    SLG     BA  Playoffs    G  new_OOBP  new_OSLG\n",
       "0  734  688  81  0.328  0.418  0.259         0  162     0.317     0.415\n",
       "1  700  600  94  0.320  0.389  0.247         1  162     0.306     0.378\n",
       "4  613  759  61  0.302  0.378  0.240         0  162     0.335     0.424\n",
       "6  669  588  97  0.315  0.411  0.251         1  162     0.305     0.390\n",
       "8  758  890  64  0.330  0.436  0.274         0  162     0.357     0.470"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########    Cleaning the dataset    ########### \n",
    "\n",
    "moneyball_temp1.drop(columns=['Team','League','Year'],inplace=True)\n",
    "moneyball_temp1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([494.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 122.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(moneyball_temp1['Playoffs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing set \n",
    "# stratify makes sure that the distribution of the 1's and 0's is the same in the splits as well\n",
    "\n",
    "y_true = moneyball_temp1['Playoffs'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(moneyball_temp1.drop(columns=['Playoffs']),moneyball_temp1['Playoffs'], \n",
    "                                                 stratify=y_true, test_size=0.2, random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([395.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  97.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the distribution of the classes\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_test)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "log_reg = LogisticRegressionCV(solver=\"lbfgs\", random_state=42, cv = 5, scoring = 'f1')\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "y_probe = log_reg.predict_proba(x_test)\n",
    "y_predict = log_reg.predict(x_test)\n",
    "y_predict_train = log_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      " \n",
      " Mean Squared error for train dataset -  0.08943089430894309 \n",
      " Mean Abs Error for train dataset -  0.08943089430894309\n",
      "\n",
      " Mean Squared error for test dataset -  0.056451612903225805 \n",
      " Mean Abs Error for test dataset -  0.056451612903225805\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression:\\n','\\n','Mean Squared error for train dataset - ',mean_squared_error(y_train,y_predict_train),\n",
    "      '\\n','Mean Abs Error for train dataset - ', mean_absolute_error(y_train,y_predict_train))\n",
    "\n",
    "print('\\n','Mean Squared error for test dataset - ',mean_squared_error(y_test,y_predict),\n",
    "      '\\n','Mean Abs Error for test dataset - ', mean_absolute_error(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9435483870967742\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "print('Accuracy score:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[96  3]\n",
      " [ 4 21]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96        99\n",
      "           1       0.88      0.84      0.86        25\n",
      "\n",
      "    accuracy                           0.94       124\n",
      "   macro avg       0.92      0.90      0.91       124\n",
      "weighted avg       0.94      0.94      0.94       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mis-classified points for Logistic Regression : 0.056451612903225805\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mis-classified points for Logistic Regression :\", np.count_nonzero((y_predict - y_test))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBClassifier model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the number of base models to upto 300 and max depth of decision trees upto 4, as I dont want to overfit.\n",
    "\n",
    "params = {\n",
    "        'n_estimators' : [50, 100, 150, 200, 250, 300], \n",
    "        'learning_rate' : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4] ,\n",
    "        'max_depth': [2, 3, 4],\n",
    "        'subsample' : [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'min_child_weight' : [1, 3, 5, 7 ],\n",
    "        'gamma' : [0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset is imbalanced, I use scale_pos_weight with the value set to [(no. of 0's) / (no. of 1's) i.e. (99/25)]\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', n_jobs=-1, scale_pos_weight=3.96, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x0000020A16488390>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, mis...\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3, 0.35,\n",
       "                                                          0.4],\n",
       "                                        'max_depth': [2, 3, 4],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=42, scoring='f1_weighted')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# referenced from https://www.kaggle.com/tilii7/hyperparameter-grid-search-with-xgboost\n",
    "\n",
    "folds = 5\n",
    "param_comb = 15\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='f1_weighted', \n",
    "                                   n_jobs=-1, cv=skf.split(x_train,y_train), random_state= 42)\n",
    "random_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([0.05133772, 0.15119829, 0.30001597, 0.23235483, 0.24750814,\n",
      "       0.24009981, 0.2444633 , 0.28879833, 0.07123342, 0.06880198,\n",
      "       0.28842239, 0.04799819, 0.07599945, 0.13039846, 0.07243695]), 'std_fit_time': array([0.01654358, 0.04167799, 0.04095902, 0.06025219, 0.06899834,\n",
      "       0.07764801, 0.06340704, 0.0889183 , 0.01744058, 0.02182256,\n",
      "       0.04258088, 0.00357852, 0.00252979, 0.06681836, 0.00413197]), 'mean_score_time': array([0.0047996 , 0.00480223, 0.01280065, 0.00400147, 0.00639973,\n",
      "       0.00480056, 0.01006832, 0.00560122, 0.00560012, 0.01439896,\n",
      "       0.01600361, 0.00400071, 0.00480194, 0.00400023, 0.01801925]), 'std_score_time': array([3.92124760e-03, 1.60253066e-03, 1.39487839e-02, 3.57872926e-03,\n",
      "       3.19986355e-03, 1.60014754e-03, 9.09394660e-03, 4.07926609e-03,\n",
      "       4.07941561e-03, 1.28007415e-02, 1.61968731e-02, 7.89305942e-07,\n",
      "       1.59981388e-03, 8.58306885e-07, 2.02887190e-02]), 'param_subsample': masked_array(data=[1.0, 0.6, 1.0, 1.0, 1.0, 0.6, 0.8, 1.0, 0.8, 1.0, 0.8,\n",
      "                   1.0, 1.0, 1.0, 0.6],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 200, 250, 150, 200, 250, 300, 250, 50, 50, 300, 50,\n",
      "                   100, 100, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[5, 3, 7, 7, 5, 1, 5, 1, 1, 1, 3, 1, 3, 7, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[3, 2, 4, 4, 4, 3, 2, 3, 2, 2, 3, 4, 4, 3, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.3, 0.1, 0.2, 0.05, 0.2, 0.4, 0.25, 0.35, 0.3, 0.35,\n",
      "                   0.25, 0.3, 0.15, 0.25, 0.15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.3, 0.4, 0.0, 0.3, 0.2, 0.1, 0.1, 0.2, 0.3, 0.4, 0.2,\n",
      "                   0.2, 0.3, 0.1, 0.4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[1.0, 0.8, 0.6, 0.6, 1.0, 0.8, 0.8, 1.0, 0.6, 0.8, 0.6,\n",
      "                   1.0, 0.8, 0.8, 0.8],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.3, 'gamma': 0.3, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 0.4, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 250, 'min_child_weight': 7, 'max_depth': 4, 'learning_rate': 0.2, 'gamma': 0.0, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 150, 'min_child_weight': 7, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.2, 'gamma': 0.2, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 250, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.4, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.25, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 250, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.35, 'gamma': 0.2, 'colsample_bytree': 1.0}, {'subsample': 0.8, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.3, 'gamma': 0.3, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.35, 'gamma': 0.4, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 300, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.25, 'gamma': 0.2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.3, 'gamma': 0.2, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 4, 'learning_rate': 0.15, 'gamma': 0.3, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 100, 'min_child_weight': 7, 'max_depth': 3, 'learning_rate': 0.25, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 100, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.15, 'gamma': 0.4, 'colsample_bytree': 0.8}], 'split0_test_score': array([0.91919192, 0.91919192, 0.91757044, 0.91919192, 0.91919192,\n",
      "       0.92708519, 0.91757044, 0.91570021, 0.94900627, 0.92993003,\n",
      "       0.90625238, 0.92860878, 0.91757044, 0.90821129, 0.92993003]), 'split1_test_score': array([0.88272334, 0.88989005, 0.89168959, 0.88272334, 0.8738364 ,\n",
      "       0.88089688, 0.88089688, 0.88089688, 0.88089688, 0.88989005,\n",
      "       0.87878788, 0.9007474 , 0.89168959, 0.88272334, 0.89168959]), 'split2_test_score': array([0.90149306, 0.90149306, 0.91200201, 0.93247135, 0.90149306,\n",
      "       0.90149306, 0.89077538, 0.87982732, 0.91200201, 0.90149306,\n",
      "       0.90149306, 0.9106344 , 0.88179168, 0.92232204, 0.91200201]), 'split3_test_score': array([0.829254  , 0.84822578, 0.829254  , 0.84086324, 0.81882983,\n",
      "       0.88179168, 0.84657794, 0.8423889 , 0.85839234, 0.83790038,\n",
      "       0.86209029, 0.83119832, 0.86575569, 0.83081912, 0.83600186]), 'split4_test_score': array([0.88493345, 0.86406357, 0.85333668, 0.89511201, 0.88179168,\n",
      "       0.84841364, 0.87289179, 0.85105734, 0.89388356, 0.87289179,\n",
      "       0.85979853, 0.86209029, 0.88348306, 0.87458966, 0.87458966]), 'mean_test_score': array([0.88351915, 0.88457287, 0.88077054, 0.89407237, 0.87902858,\n",
      "       0.88793609, 0.88174249, 0.87397413, 0.89883621, 0.88642106,\n",
      "       0.88168443, 0.88665584, 0.88805809, 0.88373309, 0.88884263]), 'std_test_score': array([0.03014282, 0.02551387, 0.03422114, 0.03183258, 0.03398891,\n",
      "       0.02594522, 0.02315526, 0.02586912, 0.03056936, 0.03055987,\n",
      "       0.01932501, 0.03524938, 0.01698094, 0.03153664, 0.03233552]), 'rank_test_score': array([10,  8, 13,  2, 14,  5, 11, 15,  1,  7, 12,  6,  4,  9,  3])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.6, gamma=0.3, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=2,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=3.96, subsample=0.8,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      " Best normalized gini score for 5-fold search with 15 parameter combinations:\n",
      "0.7976724220515319\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 0.8, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.3, 'gamma': 0.3, 'colsample_bytree': 0.6}\n"
     ]
    }
   ],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = random_search.predict_proba(x_train)\n",
    "y_predict = random_search.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_train = []\n",
    "pred_labels = []\n",
    "\n",
    "for i in y_predict_train:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels_train.append(pos)\n",
    "\n",
    "for i in y_predict:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Classifier:\n",
      " \n",
      " Mean Squared error for train dataset -  0.054878048780487805 \n",
      " Mean Abs Error for train dataset -  0.054878048780487805\n",
      "\n",
      " Mean Squared error for test dataset -  0.08064516129032258 \n",
      " Mean Abs Error for test dataset -  0.08064516129032258\n"
     ]
    }
   ],
   "source": [
    "print('GBDT Classifier:\\n','\\n','Mean Squared error for train dataset - ',mean_squared_error(y_train,pred_labels_train),\n",
    "      '\\n','Mean Abs Error for train dataset - ', mean_absolute_error(y_train,pred_labels_train))\n",
    "\n",
    "print('\\n','Mean Squared error for test dataset - ',mean_squared_error(y_test,pred_labels),\n",
    "      '\\n','Mean Abs Error for test dataset - ', mean_absolute_error(y_test,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9193548387096774"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,pred_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Test data:\n",
      " [[91  8]\n",
      " [ 2 23]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix of Test data:\\n',confusion_matrix(y_test,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        99\n",
      "           1       0.74      0.92      0.82        25\n",
      "\n",
      "    accuracy                           0.92       124\n",
      "   macro avg       0.86      0.92      0.88       124\n",
      "weighted avg       0.93      0.92      0.92       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test Data:\\n',classification_report(y_test,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mis-classified points for GBDT : 0.08064516129032258\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mis-classified points for GBDT :\", np.count_nonzero((pred_labels - y_test))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As I wanted to improve the results of RandomSearchCV further, I decided to manually tune the parameters, specifically n_estimators (number of base models) and learning_rate (balances out the increased variance caused by increasing n_estimators) to obtain optimum results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1.0, gamma=0.3, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=7, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=-1, num_parallel_tree=1, random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=3.96, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=4,\n",
    "              min_child_weight=7, n_estimators=200, n_jobs=-1, random_state=1, scale_pos_weight=3.96, \n",
    "              subsample=0.8, verbosity=None)\n",
    "final_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = final_model.predict(x_test)\n",
    "pred_y_train = final_model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Classifier: \n",
      " Mean Squared error for train dataset -  0.034552845528455285 \n",
      " Mean Abs Error for train dataset -  0.034552845528455285\n",
      "\n",
      " Mean Squared error for test dataset -  0.06451612903225806 \n",
      " Mean Abs Error for test dataset -  0.06451612903225806\n"
     ]
    }
   ],
   "source": [
    "print('GBDT Classifier:','\\n','Mean Squared error for train dataset - ',mean_squared_error(y_train,pred_y_train),\n",
    "      '\\n','Mean Abs Error for train dataset - ', mean_absolute_error(y_train,pred_y_train))\n",
    "\n",
    "print('\\n','Mean Squared error for test dataset - ',mean_squared_error(y_test,pred_y),\n",
    "      '\\n','Mean Abs Error for test dataset - ', mean_absolute_error(y_test,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9354838709677419"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,pred_y)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92  7]\n",
      " [ 1 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_y))\n",
    "#print(confusion_matrix(y_train,pred_labels_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96        99\n",
      "           1       0.77      0.96      0.86        25\n",
      "\n",
      "    accuracy                           0.94       124\n",
      "   macro avg       0.88      0.94      0.91       124\n",
      "weighted avg       0.95      0.94      0.94       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mis-classified points for GBDT : 0.06451612903225806\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mis-classified points for GBDT :\", np.count_nonzero((pred_y - y_test))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model with best results for National League: GBDT (n_estimators=200 , learning_rate=0.1 & max_depth=4) with an accuracy score of 93.5% and an f1 score of 0.96 and 0.86 for classes 0 and 1 respectively.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling for American League"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>League</th>\n",
       "      <th>Year</th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>new_OOBP</th>\n",
       "      <th>new_OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHW</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>748</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CLE</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>667</td>\n",
       "      <td>845</td>\n",
       "      <td>68</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DET</td>\n",
       "      <td>AL</td>\n",
       "      <td>2012</td>\n",
       "      <td>726</td>\n",
       "      <td>670</td>\n",
       "      <td>88</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.268</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Team League  Year   RS   RA   W    OBP    SLG     BA  Playoffs    G  \\\n",
       "2  BAL     AL  2012  712  705  93  0.311  0.417  0.247         1  162   \n",
       "3  BOS     AL  2012  734  806  69  0.315  0.415  0.260         0  162   \n",
       "5  CHW     AL  2012  748  676  85  0.318  0.422  0.255         0  162   \n",
       "7  CLE     AL  2012  667  845  68  0.324  0.381  0.251         0  162   \n",
       "9  DET     AL  2012  726  670  88  0.335  0.422  0.268         1  162   \n",
       "\n",
       "   new_OOBP  new_OSLG  \n",
       "2     0.315     0.403  \n",
       "3     0.331     0.428  \n",
       "5     0.319     0.405  \n",
       "7     0.336     0.430  \n",
       "9     0.314     0.402  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moneyball_temp2 = moneyball3.loc[moneyball3['League']=='AL'].copy()\n",
    "moneyball_temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RS</th>\n",
       "      <th>RA</th>\n",
       "      <th>W</th>\n",
       "      <th>OBP</th>\n",
       "      <th>SLG</th>\n",
       "      <th>BA</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>G</th>\n",
       "      <th>new_OOBP</th>\n",
       "      <th>new_OSLG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>712</td>\n",
       "      <td>705</td>\n",
       "      <td>93</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.247</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>734</td>\n",
       "      <td>806</td>\n",
       "      <td>69</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>748</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>667</td>\n",
       "      <td>845</td>\n",
       "      <td>68</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>726</td>\n",
       "      <td>670</td>\n",
       "      <td>88</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.268</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RS   RA   W    OBP    SLG     BA  Playoffs    G  new_OOBP  new_OSLG\n",
       "2  712  705  93  0.311  0.417  0.247         1  162     0.315     0.403\n",
       "3  734  806  69  0.315  0.415  0.260         0  162     0.331     0.428\n",
       "5  748  676  85  0.318  0.422  0.255         0  162     0.319     0.405\n",
       "7  667  845  68  0.324  0.381  0.251         0  162     0.336     0.430\n",
       "9  726  670  88  0.335  0.422  0.268         1  162     0.314     0.402"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########      Cleaning the dataset      ########### \n",
    "\n",
    "moneyball_temp2.drop(columns=['Team','League','Year'],inplace=True)\n",
    "moneyball_temp2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([494.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 122.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOnElEQVR4nO3cf6zdd13H8eeLdgwUlc7eNrUtdpqqdMYNvNZF1AAjrgxjZ8KSokJDljTGaTAxkY4/JGqadP8QYnQhDRJqFJpGwFVQtClONPwodzo2ulF3ZbO7abNehsoPk5mWt3/cr+TQ3rvzbe8593I+fT6S5ZzzOd9zzvuTNs+enXvuN1WFJKktL1jtASRJo2fcJalBxl2SGmTcJalBxl2SGrR2tQcAWL9+fW3btm21x5CkifLQQw99uaqmFrvvOyLu27ZtY2ZmZrXHkKSJkuQ/lrrPj2UkqUHGXZIaZNwlqUG94p7kqSSPJnk4yUy3dkOS40me6C7XDRx/b5LZJKeT3D6u4SVJi7uSd+6vqapbqmq6u70fOFFV24ET3W2S7AD2ADcBu4D7k6wZ4cySpCGW87HMbuBwd/0wcOfA+pGqeq6qngRmgZ3LeB1J0hXqG/cC/j7JQ0n2dWsbq+ocQHe5oVvfDDw98Ni5bu3bJNmXZCbJzPz8/NVNL0laVN/vub+qqs4m2QAcT/LF5zk2i6xddl7hqjoEHAKYnp72vMOSNEK93rlX1dnu8jzwERY+ZnkmySaA7vJ8d/gcsHXg4VuAs6MaWJI03NB37km+G3hBVX2tu/4LwB8Ax4C9wMHu8oHuIceADyR5F/ADwHbg5Bhm/5Zt+z82zqdf0lMH37AqrytJw/T5WGYj8JEk/3/8B6rq40k+BxxNcjdwBrgLoKpOJTkKPAZcAO6pqotjmV6StKihca+qLwE3L7L+LHDbEo85ABxY9nSSpKvib6hKUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoOMuyQ1yLhLUoN6xz3JmiT/muSj3e0bkhxP8kR3uW7g2HuTzCY5neT2cQwuSVralbxzfxvw+MDt/cCJqtoOnOhuk2QHsAe4CdgF3J9kzWjGlST10SvuSbYAbwDeO7C8GzjcXT8M3DmwfqSqnquqJ4FZYOdoxpUk9dH3nfu7gd8FvjmwtrGqzgF0lxu69c3A0wPHzXVr3ybJviQzSWbm5+eveHBJ0tKGxj3JLwLnq+qhns+ZRdbqsoWqQ1U1XVXTU1NTPZ9aktTH2h7HvAr4pSR3AC8CvjfJnwPPJNlUVeeSbALOd8fPAVsHHr8FODvKoSVJz2/oO/equreqtlTVNhZ+UPqJqvo14BiwtztsL/BAd/0YsCfJ9UluBLYDJ0c+uSRpSX3euS/lIHA0yd3AGeAugKo6leQo8BhwAbinqi4ue1JJUm9XFPeqehB4sLv+LHDbEscdAA4sczZJ0lXyN1QlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUHGXZIaZNwlqUFD457kRUlOJvl8klNJfr9bvyHJ8SRPdJfrBh5zb5LZJKeT3D7ODUiSLtfnnftzwGur6mbgFmBXkluB/cCJqtoOnOhuk2QHsAe4CdgF3J9kzTiGlyQtbmjca8HXu5vXdf8VsBs43K0fBu7sru8GjlTVc1X1JDAL7Bzp1JKk59XrM/cka5I8DJwHjlfVZ4GNVXUOoLvc0B2+GXh64OFz3dqlz7kvyUySmfn5+eXsQZJ0iV5xr6qLVXULsAXYmeTHn+fwLPYUizznoaqarqrpqampftNKknq5om/LVNV/AQ+y8Fn6M0k2AXSX57vD5oCtAw/bApxd9qSSpN76fFtmKslLu+svBl4HfBE4BuztDtsLPNBdPwbsSXJ9khuB7cDJUQ8uSVra2h7HbAIOd994eQFwtKo+muTTwNEkdwNngLsAqupUkqPAY8AF4J6qujie8SVJixka96p6BHjFIuvPArct8ZgDwIFlTydJuir+hqokNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNWho3JNsTfIPSR5PcirJ27r1G5IcT/JEd7lu4DH3JplNcjrJ7ePcgCTpcn3euV8AfqeqXg7cCtyTZAewHzhRVduBE91tuvv2ADcBu4D7k6wZx/CSpMUNjXtVnauqf+mufw14HNgM7AYOd4cdBu7sru8GjlTVc1X1JDAL7Bz14JKkpV3RZ+5JtgGvAD4LbKyqc7DwDwCwoTtsM/D0wMPmurVLn2tfkpkkM/Pz81c+uSRpSb3jnuQlwIeA366qrz7foYus1WULVYeqarqqpqempvqOIUnqoVfck1zHQtj/oqo+3C0/k2RTd/8m4Hy3PgdsHXj4FuDsaMaVJPXR59syAf4UeLyq3jVw1zFgb3d9L/DAwPqeJNcnuRHYDpwc3ciSpGHW9jjmVcCbgUeTPNytvQM4CBxNcjdwBrgLoKpOJTkKPMbCN23uqaqLI59ckrSkoXGvqn9m8c/RAW5b4jEHgAPLmEuStAz+hqokNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNci4S1KDjLskNWjtag8gSatt2/6PrdprP3XwDWN5Xt+5S1KDjLskNci4S1KDjLskNci4S1KDhsY9yfuSnE/yhYG1G5IcT/JEd7lu4L57k8wmOZ3k9nENLklaWp937u8Hdl2yth84UVXbgRPdbZLsAPYAN3WPuT/JmpFNK0nqZWjcq+qTwFcuWd4NHO6uHwbuHFg/UlXPVdWTwCywc0SzSpJ6utrP3DdW1TmA7nJDt74ZeHrguLlu7TJJ9iWZSTIzPz9/lWNIkhYz6h+oZpG1WuzAqjpUVdNVNT01NTXiMSTp2na1cX8mySaA7vJ8tz4HbB04bgtw9urHkyRdjauN+zFgb3d9L/DAwPqeJNcnuRHYDpxc3oiSpCs19MRhST4IvBpYn2QOeCdwEDia5G7gDHAXQFWdSnIUeAy4ANxTVRfHNLskaQlD415Vb1rirtuWOP4AcGA5Q0mSlsffUJWkBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBo0t7kl2JTmdZDbJ/nG9jiTpcmOJe5I1wJ8Arwd2AG9KsmMcryVJuty43rnvBGar6ktV9b/AEWD3mF5LknSJtWN63s3A0wO354CfHjwgyT5gX3fz60lOL+P11gNfXsbjr0ruW+lX/JZV2e8qc8/Xhmtuz7lvWXv+waXuGFfcs8hafduNqkPAoZG8WDJTVdOjeK5JcK3tF9zztcI9j864PpaZA7YO3N4CnB3Ta0mSLjGuuH8O2J7kxiQvBPYAx8b0WpKkS4zlY5mqupDkN4G/A9YA76uqU+N4rc5IPt6ZINfafsE9Xyvc84ikqoYfJUmaKP6GqiQ1yLhLUoMmJu7DTmeQBX/U3f9Ikleuxpyj1GPPv9rt9ZEkn0py82rMOUp9T1uR5KeSXEzyxpWcbxz67DnJq5M8nORUkn9c6RlHrcff7e9L8tdJPt/t+a2rMeeoJHlfkvNJvrDE/aPvV1V9x//Hwg9l/x34IeCFwOeBHZcccwfwtyx8x/5W4LOrPfcK7PlngHXd9ddfC3seOO4TwN8Ab1ztuVfgz/mlwGPAy7rbG1Z77hXY8zuA+7rrU8BXgBeu9uzL2PPPA68EvrDE/SPv16S8c+9zOoPdwJ/Vgs8AL02yaaUHHaGhe66qT1XVf3Y3P8PC7xNMsr6nrfgt4EPA+ZUcbkz67PlXgA9X1RmAqpr0fffZcwHfkyTAS1iI+4WVHXN0quqTLOxhKSPv16TEfbHTGWy+imMmyZXu524W/uWfZEP3nGQz8MvAe1ZwrnHq8+f8I8C6JA8meSjJW1ZsuvHos+c/Bl7Owi8/Pgq8raq+uTLjrYqR92tcpx8YtaGnM+h5zCTpvZ8kr2Eh7j871onGr8+e3w28vaouLrypm3h99rwW+EngNuDFwKeTfKaq/m3cw41Jnz3fDjwMvBb4YeB4kn+qqq+Oe7hVMvJ+TUrc+5zOoLVTHvTaT5KfAN4LvL6qnl2h2calz56ngSNd2NcDdyS5UFV/tTIjjlzfv9tfrqpvAN9I8kngZmBS495nz28FDtbCB9KzSZ4Efgw4uTIjrriR92tSPpbpczqDY8Bbup863wr8d1WdW+lBR2jonpO8DPgw8OYJfhc3aOieq+rGqtpWVduAvwR+Y4LDDv3+bj8A/FyStUm+i4UzrD6+wnOOUp89n2Hh/1RIshH4UeBLKzrlyhp5vybinXstcTqDJL/e3f8eFr45cQcwC/wPC//yT6yee/494PuB+7t3shdqgs+o13PPTemz56p6PMnHgUeAbwLvrapFv1I3CXr+Of8h8P4kj7LwkcXbq2piTwWc5IPAq4H1SeaAdwLXwfj65ekHJKlBk/KxjCTpChh3SWqQcZekBhl3SWqQcZekBhl3SWqQcZekBv0fZI7PBYnTdmQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(moneyball_temp2['Playoffs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We have a skewed feature to predict as the classes '0' and '1' are not balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing set \n",
    "y_true = moneyball_temp2['Playoffs'].values\n",
    "x_train,x_test,y_train,y_test = train_test_split(moneyball_temp2.drop(columns=['Playoffs']),moneyball_temp2['Playoffs'],\n",
    "                                                 stratify = y_true, test_size=0.2, random_state=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([395.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  97.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming the distribution of the classes\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(y_test)\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "log_reg = LogisticRegressionCV(solver='lbfgs', cv=5, scoring='f1', random_state=42)\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "y_probe = log_reg.predict_proba(x_test)\n",
    "y_predict = log_reg.predict(x_test)\n",
    "y_predict_train = log_reg.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      " \n",
      " Mean Squared error for train dataset -  0.06910569105691057 \n",
      " Mean Abs Error for train dataset -  0.06910569105691057\n",
      "\n",
      " Mean Squared error for test dataset -  0.08064516129032258 \n",
      " Mean Abs Error for test dataset -  0.08064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the performance of the trained model with different metrics \n",
    "\n",
    "print('Logistic Regression:\\n','\\n','Mean Squared error for train dataset - ',mean_squared_error(y_train,y_predict_train),\n",
    "      '\\n','Mean Abs Error for train dataset - ', mean_absolute_error(y_train,y_predict_train))\n",
    "\n",
    "print('\\n','Mean Squared error for test dataset - ',mean_squared_error(y_test,y_predict),\n",
    "      '\\n','Mean Abs Error for test dataset - ', mean_absolute_error(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9193548387096774"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,y_predict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[95  4]\n",
      " [ 6 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        99\n",
      "           1       0.83      0.76      0.79        25\n",
      "\n",
      "    accuracy                           0.92       124\n",
      "   macro avg       0.88      0.86      0.87       124\n",
      "weighted avg       0.92      0.92      0.92       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mis-classified points for Logistic Regression : 0.08064516129032258\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mis-classified points for Logistic Regression :\", np.count_nonzero((y_predict - y_test))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the number of base models to upto 300 and max depth of decision trees upto 4, as I dont want to overfit.\n",
    "\n",
    "params = {\n",
    "        'n_estimators' : [50, 100, 150, 200, 250, 300],\n",
    "        'learning_rate' : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.4] ,\n",
    "        'max_depth': [2, 3, 4],\n",
    "        'subsample' : [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'min_child_weight' : [1, 3, 5, 7 ],\n",
    "        'gamma' : [0.0, 0.1, 0.2 , 0.3, 0.4]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the dataset is imbalanced, I use scale_pos_weight with the value set to [(no. of 0's) / (no. of 1's) i.e. (99/25)]\n",
    "\n",
    "xgb = XGBClassifier(objective='binary:logistic', n_jobs=-1, scale_pos_weight=3.96, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x0000020A167FFC00>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, mis...\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3, 0.35,\n",
       "                                                          0.4],\n",
       "                                        'max_depth': [2, 3, 4],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'n_estimators': [50, 100, 150, 200, 250,\n",
       "                                                         300],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1, scoring='f1_weighted')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = 5\n",
    "param_comb = 15\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state = 42)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, scoring='f1_weighted', \n",
    "                                   n_jobs=-1, cv=skf.split(x_train,y_train), random_state= 1, n_iter=param_comb)\n",
    "random_search.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([0.03839703, 0.07999821, 0.08480029, 0.22399979, 0.21149354,\n",
      "       0.07364631, 0.08160205, 0.0911984 , 0.08319936, 0.30090661,\n",
      "       0.12263923, 0.16812353, 0.21005926, 0.13085885, 0.06560616]), 'std_fit_time': array([0.00598534, 0.00876275, 0.00391851, 0.05085243, 0.06337621,\n",
      "       0.00940384, 0.01376365, 0.02609711, 0.01084949, 0.07646015,\n",
      "       0.02707483, 0.05014302, 0.08437941, 0.02844161, 0.03185501]), 'mean_score_time': array([0.00320172, 0.0047997 , 0.00159998, 0.00639944, 0.00559788,\n",
      "       0.00160003, 0.01279945, 0.00160036, 0.00479865, 0.00640011,\n",
      "       0.00400062, 0.00240107, 0.00400038, 0.01520014, 0.00559998]), 'std_score_time': array([3.92129398e-03, 3.91893862e-03, 3.19995880e-03, 5.98600128e-03,\n",
      "       4.79704677e-03, 3.20005417e-03, 1.39506165e-02, 3.20072174e-03,\n",
      "       3.91808225e-03, 3.20005426e-03, 3.57851574e-03, 1.96046212e-03,\n",
      "       1.29186794e-06, 2.24001409e-02, 5.98675328e-03]), 'param_subsample': masked_array(data=[0.8, 0.8, 1.0, 0.6, 1.0, 0.8, 0.8, 1.0, 0.6, 1.0, 0.6,\n",
      "                   1.0, 0.6, 0.6, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 150, 200, 200, 50, 50, 50, 50, 300, 150, 200,\n",
      "                   200, 150, 50],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[3, 1, 1, 1, 1, 5, 7, 7, 1, 1, 7, 5, 5, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[2, 3, 2, 2, 4, 2, 2, 2, 4, 3, 3, 4, 4, 2, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.1, 0.05, 0.05, 0.05, 0.15, 0.25, 0.1, 0.2, 0.05, 0.4,\n",
      "                   0.2, 0.2, 0.15, 0.05, 0.4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[0.0, 0.2, 0.3, 0.0, 0.1, 0.4, 0.1, 0.2, 0.0, 0.1, 0.4,\n",
      "                   0.4, 0.1, 0.2, 0.4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_colsample_bytree': masked_array(data=[0.6, 0.8, 0.6, 1.0, 0.8, 0.6, 1.0, 1.0, 0.6, 1.0, 0.8,\n",
      "                   0.6, 0.8, 0.6, 1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'subsample': 0.8, 'n_estimators': 50, 'min_child_weight': 3, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 0.0, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 100, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.05, 'gamma': 0.3, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.05, 'gamma': 0.0, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.15, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.8, 'n_estimators': 50, 'min_child_weight': 5, 'max_depth': 2, 'learning_rate': 0.25, 'gamma': 0.4, 'colsample_bytree': 0.6}, {'subsample': 0.8, 'n_estimators': 50, 'min_child_weight': 7, 'max_depth': 2, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 7, 'max_depth': 2, 'learning_rate': 0.2, 'gamma': 0.2, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 4, 'learning_rate': 0.05, 'gamma': 0.0, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.4, 'gamma': 0.1, 'colsample_bytree': 1.0}, {'subsample': 0.6, 'n_estimators': 150, 'min_child_weight': 7, 'max_depth': 3, 'learning_rate': 0.2, 'gamma': 0.4, 'colsample_bytree': 0.8}, {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.2, 'gamma': 0.4, 'colsample_bytree': 0.6}, {'subsample': 0.6, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 4, 'learning_rate': 0.15, 'gamma': 0.1, 'colsample_bytree': 0.8}, {'subsample': 0.6, 'n_estimators': 150, 'min_child_weight': 1, 'max_depth': 2, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.6}, {'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.4, 'gamma': 0.4, 'colsample_bytree': 1.0}], 'split0_test_score': array([0.91138239, 0.91919192, 0.90226945, 0.90821129, 0.91757044,\n",
      "       0.91757044, 0.90226945, 0.92059792, 0.8989899 , 0.92860878,\n",
      "       0.89696305, 0.91757044, 0.92860878, 0.88781379, 0.94900627]), 'split1_test_score': array([0.90991004, 0.8989899 , 0.8989899 , 0.8989899 , 0.90625238,\n",
      "       0.8989899 , 0.88989005, 0.8989899 , 0.90821129, 0.90625238,\n",
      "       0.88781379, 0.88781379, 0.88781379, 0.8989899 , 0.90625238]), 'split2_test_score': array([0.89511201, 0.91317746, 0.90411121, 0.91317746, 0.94089584,\n",
      "       0.90411121, 0.90514111, 0.93155712, 0.91317746, 0.93049342,\n",
      "       0.91418255, 0.93155712, 0.92119445, 0.90411121, 0.94089584]), 'split3_test_score': array([0.87727336, 0.88616933, 0.88616933, 0.88616933, 0.88616933,\n",
      "       0.88616933, 0.88721275, 0.89511201, 0.88493345, 0.91317746,\n",
      "       0.88721275, 0.88616933, 0.88616933, 0.87727336, 0.90411121]), 'split4_test_score': array([0.95035245, 0.93991366, 0.95035245, 0.94947121, 0.91660998,\n",
      "       0.93991366, 0.93991366, 0.93991366, 0.95035245, 0.92617569,\n",
      "       0.93745748, 0.93877551, 0.9278308 , 0.93991366, 0.95918367]), 'mean_test_score': array([0.90880605, 0.91148845, 0.90837847, 0.91120384, 0.91349959,\n",
      "       0.90935091, 0.9048854 , 0.91723412, 0.91113291, 0.92094155,\n",
      "       0.90472593, 0.91237724, 0.91032343, 0.90162038, 0.93188988]), 'std_test_score': array([0.02414869, 0.01826176, 0.02190313, 0.02122804, 0.01775537,\n",
      "       0.01829663, 0.01882058, 0.01762421, 0.0218392 , 0.00952338,\n",
      "       0.01904614, 0.02182624, 0.01923094, 0.02127392, 0.02257417]), 'rank_test_score': array([11,  6, 12,  7,  4, 10, 13,  3,  8,  2, 14,  5,  9, 15,  1])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1.0, gamma=0.4, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.4, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=50, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=3.96, subsample=1.0,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "\n",
      " Best normalized gini score for 5-fold search with 15 parameter combinations:\n",
      "0.8637797505199694\n",
      "\n",
      " Best hyperparameters:\n",
      "{'subsample': 1.0, 'n_estimators': 50, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.4, 'gamma': 0.4, 'colsample_bytree': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print('\\n All results:')\n",
    "print(random_search.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(random_search.best_estimator_)\n",
    "print('\\n Best normalized gini score for %d-fold search with %d parameter combinations:' % (folds, param_comb))\n",
    "print(random_search.best_score_ * 2 - 1)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_train = random_search.predict_proba(x_train)\n",
    "y_predict = random_search.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_train = []\n",
    "pred_labels = []\n",
    "\n",
    "for i in y_predict_train:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels_train.append(pos)\n",
    "\n",
    "for i in y_predict:\n",
    "    i = list(i)\n",
    "    pos = i.index(max(i))\n",
    "    pred_labels.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT Classifier:\n",
      " \n",
      " Mean Squared error for train dataset -  0.0020325203252032522 \n",
      " Mean Abs Error for train dataset -  0.0020325203252032522\n",
      "\n",
      " Mean Squared error for test dataset -  0.0967741935483871 \n",
      " Mean Abs Error for test dataset -  0.0967741935483871\n"
     ]
    }
   ],
   "source": [
    "print('GBDT Classifier:\\n','\\n','Mean Squared error for train dataset - ',mean_squared_error(y_train,pred_labels_train),\n",
    "      '\\n','Mean Abs Error for train dataset - ', mean_absolute_error(y_train,pred_labels_train))\n",
    "\n",
    "print('\\n','Mean Squared error for test dataset - ',mean_squared_error(y_test,pred_labels),\n",
    "      '\\n','Mean Abs Error for test dataset - ', mean_absolute_error(y_test,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9032258064516129\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,pred_labels)\n",
    "print('Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[92  7]\n",
      " [ 5 20]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        99\n",
      "           1       0.74      0.80      0.77        25\n",
      "\n",
      "    accuracy                           0.90       124\n",
      "   macro avg       0.84      0.86      0.85       124\n",
      "weighted avg       0.91      0.90      0.90       124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassification %age for GBDT : 0.0967741935483871\n"
     ]
    }
   ],
   "source": [
    "print('Misclassification %age for GBDT :', np.count_nonzero((pred_labels - y_test))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model with best results for American League: Logistic Regression with 91.9% accuracy and an f1 score of 0.95 and 0.79 for classes 0 and 1 respectively.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
